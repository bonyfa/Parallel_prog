# Parallel_prog
 
ООтчет по лабораторной работе №3
Параллельное умножение матриц с использованием MPI

Технические характеристики
Оборудование: Суперкомпьютер "Сергей Королёв"

Результаты экспериментов
Таблица времени выполнения (секунды)
Размер	Последовательная	4 процесса	12 процессов	Ускорение (4p)	Ускорение (12p)
100	0.0108	0.00131	0.00143	8.24x	7.55x
200	0.1135	0.01061	0.00887	10.70x	12.80x
300	0.3067	0.03135	0.02458	9.78x	12.47x
400	0.6762	0.07937	0.04615	8.52x	14.65x
500	1.3357	0.14337	0.08652	9.32x	15.44x
600	2.3715	0.23343	0.14187	10.16x	16.72x
700	3.7705	0.37765	0.22632	9.98x	16.66x
800	5.6101	0.58185	0.34162	9.64x	16.42x
900	8.1979	0.83974	0.49759	9.76x	16.48x
1000	10.8303	1.13488	0.66353	9.54x	16.32x

Вывод
Использование MPI позволило эффективно распараллелить вычисления. Прирост производительности получился лучше, чем при использовании OpenMP, особенно при работе с большими матрицами. Однако масштабируемость ограничивается накладными расходами на передачу данных и синхронизацию между процессами.
MPI показал себя как надёжный способ распараллеливания на распределённых системах, особенно при отсутствии общего доступа к памяти.